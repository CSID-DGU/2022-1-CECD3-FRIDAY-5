{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Load_saved_model.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"LxpqxAwIncGo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Colab 환경설정\n","\n","!pip install gluonnlp pandas tqdm\n","!pip install mxnet\n","!pip install sentencepiece==0.1.91\n","!pip install transformers==4.8.2\n","!pip install torch==1.8.1"],"metadata":{"id":"4wvmY1nHrUMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# github에서 Kobert 파일 로드 및 Kobert 모델 불러오기\n","\n","#kobert_tokenizer 폴더 다운받는 코드\n","!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n","\n","#https://github.com/SKTBrain/KoBERT 의 파일들을 다운받는 코드\n","!pip install 'git+https://git@github.com/SKTBrain/KoBERT.git@master'\n","\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","from kobert_tokenizer import KoBERTTokenizer\n","tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n","bertmodel, vocab = get_pytorch_kobert_model()"],"metadata":{"id":"YTNR3bo2rU9z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 필요한 라이브러리 불러오기\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","import pandas as pd\n","\n","#transformers\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","from transformers import BertModel\n","\n","#GPU 사용 시\n","device = torch.device(\"cuda:0\")"],"metadata":{"id":"0NZX20gnreWr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 입력 데이터셋을 토큰화하기\n","\n","# 각 데이터가 BERT 모델의 입력으로 들어갈 수 있도록 tokenization, int encoding padding 등을 해주는 코드이다.\n","class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n","                 pad, pair):\n","   \n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n","        \n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","         \n","\n","    def __len__(self):\n","        return (len(self.labels))"],"metadata":{"id":"NW-6oVK8rgvP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setting parameters\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 5  \n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"],"metadata":{"id":"rCJIDBIssK3_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=7,   ##클래스 수 조정##\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device),return_dict=False)\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"metadata":{"id":"GSrhvr65sSIK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 학습 모델 로드\n","PATH = 'drive/MyDrive/colab/baseModel/'\n","model = torch.load(PATH + 'baseModel.pt')  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\n","model.load_state_dict(torch.load(PATH + 'baseModel_state_dict.pt'))  # state_dict를 불러 온 후, 모델에 저장"],"metadata":{"id":"OnZ9JXZNshY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#토큰화\n","tok=tokenizer.tokenize"],"metadata":{"id":"wT3TLhu7skYr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 예측 모델 설정\n","def predict(predict_sentence):\n","\n","    data = [predict_sentence, '0']\n","    dataset_another = [data]\n","\n","    another_test = BERTDataset(dataset_another, 0, 1, tok, vocab, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n","    \n","    model.eval()\n","\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","\n","        test_eval=[]\n","        for i in out:\n","            logits=i\n","            logits = logits.detach().cpu().numpy()\n","\n","            if np.argmax(logits) == 0:\n","                test_eval.append(\"공포가\")\n","            elif np.argmax(logits) == 1:\n","                test_eval.append(\"놀람이\")\n","            elif np.argmax(logits) == 2:\n","                test_eval.append(\"분노가\")\n","            elif np.argmax(logits) == 3:\n","                test_eval.append(\"슬픔이\")\n","            elif np.argmax(logits) == 4:\n","                test_eval.append(\"중립이\")\n","            elif np.argmax(logits) == 5:\n","                test_eval.append(\"행복이\")\n","            elif np.argmax(logits) == 6:\n","                test_eval.append(\"혐오가\")\n","\n","        print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")"],"metadata":{"id":"u6_Du6iWttog"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#질문 무한반복하기! 0 입력시 종료\n","end = 1\n","while end == 1 :\n","    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n","    if sentence == \"0\" :\n","        break\n","    predict(sentence)\n","    print(\"\\n\")"],"metadata":{"id":"6vsvZlGWmCnv"},"execution_count":null,"outputs":[]}]}